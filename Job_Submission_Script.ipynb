{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Rishit-dagli/Smart-Queuing-System-On-Edge/blob/master/Job_Submission_Script.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create Job Submission Script\n",
    "\n",
    "The next step is to create our job submission script. In the cell below, you will need to complete the job submission script and run the cell to generate the file using the magic `%%writefile` command. Your main task is to complete the following items of the script:\n",
    "\n",
    "* Create a variable `MODEL` and assign it the value of the first argument passed to the job submission script.\n",
    "* Create a variable `DEVICE` and assign it the value of the second argument passed to the job submission script.\n",
    "* Create a variable `VIDEO` and assign it the value of the third argument passed to the job submission script.\n",
    "* Create a variable `PEOPLE` and assign it the value of the sixth argument passed to the job submission script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%writefile queue_job.sh\n",
    "#!/bin/bash\n",
    "\n",
    "exec 1>/output/stdout.log 2>/output/stderr.log\n",
    "\n",
    "# Create MODEL variable\n",
    "MODEL=$1\n",
    "\n",
    "# Create DEVICE variable\n",
    "DEVICE=$2\n",
    "\n",
    "# Create VIDEO variable\n",
    "VIDEO=$3\n",
    "\n",
    "QUEUE=$4\n",
    "OUTPUT=$5\n",
    "\n",
    "# TODO: Create PEOPLE variable\n",
    "PEOPLE=$6\n",
    "\n",
    "mkdir -p $5\n",
    "\n",
    "if echo \"$DEVICE\" | grep -q \"FPGA\"; then # if device passed in is FPGA, load bitstream to program FPGA\n",
    "    #Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    export AOCL_BOARD_PACKAGE_ROOT=/opt/intel/openvino/bitstreams/a10_vision_design_sg2_bitstreams/BSP/a10_1150_sg2\n",
    "\n",
    "    source /opt/altera/aocl-pro-rte/aclrte-linux64/init_opencl.sh\n",
    "    aocl program acl0 /opt/intel/openvino/bitstreams/a10_vision_design_sg2_bitstreams/2020-2_PL2_FP16_MobileNet_Clamp.aocx\n",
    "\n",
    "    export CL_CONTEXT_COMPILER_MODE_INTELFPGA=3\n",
    "fi\n",
    "\n",
    "python3 person_detect.py  --model ${MODEL} \\\n",
    "                          --device ${DEVICE} \\\n",
    "                          --video ${VIDEO} \\\n",
    "                          --queue_param ${QUEUE} \\\n",
    "                          --output_path ${OUTPUT}\\\n",
    "                          --max_people ${PEOPLE} \\\n",
    "\n",
    "cd /output\n",
    "\n",
    "tar zcvf output.tgz *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "\n",
    "Now that you've run the above cell and created your job submission script, you will run each scenarios notebook in the next three notebooks. In each of these notebooks, you will submit jobs to Intel's DevCloud to load and run inference on each type of hardware and then review the results."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
